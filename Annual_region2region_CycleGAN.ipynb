{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and save the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annual_data_EIAPacific = pd.read_pickle(\"./Datapreprocess/PreprocessedData/annual_data_EIAPacific.pickle\")\n",
    "annual_data_PSTexas = pd.read_pickle(\"./Datapreprocess/PreprocessedData/annual_data_PSTexas.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annual_data_EIAPacific.drop(['HouseholdID','REGIONC','DIVISION'],axis=1,inplace=True)\n",
    "annual_data_PSTexas.drop('HouseholdID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SD_Texas = StandardScaler()\n",
    "annual_data_PSTexas_SD = SD_Texas.fit(annual_data_PSTexas).transform(annual_data_PSTexas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SD_Pacific = StandardScaler()\n",
    "annual_data_EIAPacific_SD = SD_Pacific.fit(annual_data_EIAPacific).transform(annual_data_EIAPacific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Scaler/SD_Pacific']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(SD_Pacific,'./Scaler/SD_Pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build the data pipeline for training\n",
    "def input_fn(df,batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df)\n",
    "    dataset = dataset.shuffle(400)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CycleGeneratorXY(tf.keras.Model): #generator from Texas to pacific\n",
    "    def __init__(self,input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_dense1 = tf.keras.layers.Dense(64)\n",
    "        self.encoder_bh1 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense2 = tf.keras.layers.Dense(128)\n",
    "        self.encoder_bh2 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense3 = tf.keras.layers.Dense(256)\n",
    "        self.encoder_bh3 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense4 = tf.keras.layers.Dense(512)\n",
    "        self.encoder_bh4 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense5 = tf.keras.layers.Dense(1024)\n",
    "        self.encoder_bh5 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense6 = tf.keras.layers.Dense(512)\n",
    "        self.encoder_bh6 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense7 = tf.keras.layers.Dense(128)\n",
    "        self.encoder_bh7 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense8 = tf.keras.layers.Dense(64)\n",
    "        self.encoder_bh8 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense9 = tf.keras.layers.Dense(input_shape)\n",
    "\n",
    "    def call(self,x,is_training):\n",
    "        x=self.encoder_dense1(x)\n",
    "        x=self.encoder_bh1(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense2(x)\n",
    "        x=self.encoder_bh2(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense3(x)\n",
    "        x=self.encoder_bh3(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense4(x)\n",
    "        x=self.encoder_bh4(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense5(x)\n",
    "        x=self.encoder_bh5(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense6(x)\n",
    "        x=self.encoder_bh6(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense7(x)\n",
    "        x=self.encoder_bh7(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense8(x)\n",
    "        x=self.encoder_bh8(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense9(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class CycleGeneratorYX(tf.keras.Model):\n",
    "    def __init__(self,input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_dense1 = tf.keras.layers.Dense(64)\n",
    "        self.encoder_bh1 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense2 = tf.keras.layers.Dense(128)\n",
    "        self.encoder_bh2 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense3 = tf.keras.layers.Dense(256)\n",
    "        self.encoder_bh3 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense4 = tf.keras.layers.Dense(512)\n",
    "        self.encoder_bh4 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense5 = tf.keras.layers.Dense(1024)\n",
    "        self.encoder_bh5 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense6 = tf.keras.layers.Dense(512)\n",
    "        self.encoder_bh6 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense7 = tf.keras.layers.Dense(128)\n",
    "        self.encoder_bh7 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense8 = tf.keras.layers.Dense(64)\n",
    "        self.encoder_bh8 = tf.keras.layers.BatchNormalization()\n",
    "        self.encoder_dense9 = tf.keras.layers.Dense(input_shape)\n",
    "\n",
    "    def call(self,x,is_training):\n",
    "        x=self.encoder_dense1(x)\n",
    "        x=self.encoder_bh1(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense2(x)\n",
    "        x=self.encoder_bh2(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense3(x)\n",
    "        x=self.encoder_bh3(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense4(x)\n",
    "        x=self.encoder_bh4(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense5(x)\n",
    "        x=self.encoder_bh5(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense6(x)\n",
    "        x=self.encoder_bh6(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense7(x)\n",
    "        x=self.encoder_bh7(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense8(x)\n",
    "        x=self.encoder_bh8(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        #x=tf.nn.tanh(x)\n",
    "        x=self.encoder_dense9(x)\n",
    "        return x\n",
    "    \n",
    "class CycleDiscriminatorY(tf.keras.Model): #discriminator for synthetic pacific data\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.dis_dense1 = tf.keras.layers.Dense(64)\n",
    "        self.dis_bh1 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense2 = tf.keras.layers.Dense(256)\n",
    "        self.dis_bh2 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense3 = tf.keras.layers.Dense(512)\n",
    "        self.dis_bh3 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense4 = tf.keras.layers.Dense(256)\n",
    "        self.dis_bh4 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense5 = tf.keras.layers.Dense(64)\n",
    "        self.dis_bh5 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense6 = tf.keras.layers.Dense(32)\n",
    "        self.dis_bh6 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense7 = tf.keras.layers.Dense(1) \n",
    "\n",
    "    def call(self,x,is_training):\n",
    "        x=self.dis_dense1(x)\n",
    "        x=self.dis_bh1(x,training=is_training)\n",
    "        \n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense2(x)\n",
    "        x=self.dis_bh2(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense3(x)\n",
    "        x=self.dis_bh3(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense4(x)\n",
    "        x=self.dis_bh4(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense5(x)\n",
    "        x=self.dis_bh5(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        x=self.dis_dense6(x)\n",
    "        x=self.dis_bh6(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        x=self.dis_dense7(x)\n",
    "        x=tf.nn.sigmoid(x)\n",
    "        return x \n",
    "\n",
    "class CycleDiscriminatorX(tf.keras.Model): #discriminator for synthetic Texas data\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.dis_dense1 = tf.keras.layers.Dense(64)\n",
    "        self.dis_bh1 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense2 = tf.keras.layers.Dense(256)\n",
    "        self.dis_bh2 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense3 = tf.keras.layers.Dense(512)\n",
    "        self.dis_bh3 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense4 = tf.keras.layers.Dense(256)\n",
    "        self.dis_bh4 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense5 = tf.keras.layers.Dense(64)\n",
    "        self.dis_bh5 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense6 = tf.keras.layers.Dense(32)\n",
    "        self.dis_bh6 = tf.keras.layers.BatchNormalization()\n",
    "        self.dis_dense7 = tf.keras.layers.Dense(1) \n",
    "\n",
    "    def call(self,x,is_training):\n",
    "        x=self.dis_dense1(x)\n",
    "        x=self.dis_bh1(x,training=is_training)\n",
    "        \n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense2(x)\n",
    "        x=self.dis_bh2(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense3(x)\n",
    "        x=self.dis_bh3(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense4(x)\n",
    "        x=self.dis_bh4(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        #x=tf.nn.sigmoid(x)\n",
    "        x=self.dis_dense5(x)\n",
    "        x=self.dis_bh5(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        x=self.dis_dense6(x)\n",
    "        x=self.dis_bh6(x,training=is_training)\n",
    "        x= tf.nn.leaky_relu(x)\n",
    "        x=self.dis_dense7(x)   \n",
    "        x=tf.nn.sigmoid(x)\n",
    "        return x \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Texas_data_annual = input_fn(annual_data_PSTexas_SD,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pacific_data_annual = input_fn(annual_data_EIAPacific_SD,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=15\n",
    "batch_size = 256\n",
    "epoch = 2000\n",
    "learning_rate = 0.001\n",
    "GeneratorXY = CycleGeneratorXY(input_shape)\n",
    "DiscriminatorY= CycleDiscriminatorY()\n",
    "GeneratorYX = CycleGeneratorYX(input_shape)\n",
    "DiscriminatorX= CycleDiscriminatorX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001: GXY_loss: 54.13343, GY_loss: 1.44988,GYX_loss: 54.06897, GX_loss: 1.50475\n",
      "X reconstruct loss: 0.86013\n",
      "Y reconstruct loss: 0.92812\n",
      "Epoch 00011: GXY_loss: 24.71245, GY_loss: 1.32839,GYX_loss: 24.66985, GX_loss: 1.32378\n",
      "X reconstruct loss: 0.36310\n",
      "Y reconstruct loss: 0.44202\n",
      "Epoch 00021: GXY_loss: 17.97403, GY_loss: 1.28972,GYX_loss: 17.94602, GX_loss: 1.26719\n",
      "X reconstruct loss: 0.27900\n",
      "Y reconstruct loss: 0.30104\n",
      "Epoch 00031: GXY_loss: 15.52875, GY_loss: 1.24537,GYX_loss: 15.49689, GX_loss: 1.23695\n",
      "X reconstruct loss: 0.22037\n",
      "Y reconstruct loss: 0.27752\n",
      "Epoch 00041: GXY_loss: 13.10623, GY_loss: 1.21551,GYX_loss: 13.07665, GX_loss: 1.21442\n",
      "X reconstruct loss: 0.18507\n",
      "Y reconstruct loss: 0.23162\n",
      "Epoch 00051: GXY_loss: 11.72790, GY_loss: 1.18957,GYX_loss: 11.69464, GX_loss: 1.19642\n",
      "X reconstruct loss: 0.16272\n",
      "Y reconstruct loss: 0.20771\n",
      "Epoch 00061: GXY_loss: 11.66835, GY_loss: 1.17606,GYX_loss: 11.63996, GX_loss: 1.17846\n",
      "X reconstruct loss: 0.15785\n",
      "Y reconstruct loss: 0.21040\n",
      "Epoch 00071: GXY_loss: 10.02111, GY_loss: 1.16095,GYX_loss: 9.99471, GX_loss: 1.16577\n",
      "X reconstruct loss: 0.14101\n",
      "Y reconstruct loss: 0.17211\n",
      "Epoch 00081: GXY_loss: 9.01463, GY_loss: 1.14439,GYX_loss: 8.98804, GX_loss: 1.14587\n",
      "X reconstruct loss: 0.12482\n",
      "Y reconstruct loss: 0.15446\n",
      "Epoch 00091: GXY_loss: 9.12697, GY_loss: 1.13627,GYX_loss: 9.09798, GX_loss: 1.14283\n",
      "X reconstruct loss: 0.12561\n",
      "Y reconstruct loss: 0.15730\n",
      "Epoch 00101: GXY_loss: 8.37253, GY_loss: 1.12576,GYX_loss: 8.34387, GX_loss: 1.13859\n",
      "X reconstruct loss: 0.11682\n",
      "Y reconstruct loss: 0.14078\n",
      "Epoch 00111: GXY_loss: 8.22325, GY_loss: 1.11866,GYX_loss: 8.19744, GX_loss: 1.12504\n",
      "X reconstruct loss: 0.10767\n",
      "Y reconstruct loss: 0.14485\n",
      "Epoch 00121: GXY_loss: 7.45250, GY_loss: 1.11475,GYX_loss: 7.42778, GX_loss: 1.12473\n",
      "X reconstruct loss: 0.09794\n",
      "Y reconstruct loss: 0.12883\n",
      "Epoch 00131: GXY_loss: 7.62976, GY_loss: 1.10818,GYX_loss: 7.60583, GX_loss: 1.11067\n",
      "X reconstruct loss: 0.09453\n",
      "Y reconstruct loss: 0.13802\n",
      "Epoch 00141: GXY_loss: 8.06334, GY_loss: 1.11024,GYX_loss: 8.04016, GX_loss: 1.11628\n",
      "X reconstruct loss: 0.11147\n",
      "Y reconstruct loss: 0.13550\n",
      "Epoch 00151: GXY_loss: 7.29205, GY_loss: 1.09527,GYX_loss: 7.26856, GX_loss: 1.10244\n",
      "X reconstruct loss: 0.09868\n",
      "Y reconstruct loss: 0.12242\n",
      "Epoch 00161: GXY_loss: 7.28828, GY_loss: 1.09479,GYX_loss: 7.26589, GX_loss: 1.09564\n",
      "X reconstruct loss: 0.09512\n",
      "Y reconstruct loss: 0.12584\n",
      "Epoch 00171: GXY_loss: 7.16724, GY_loss: 1.09204,GYX_loss: 7.14291, GX_loss: 1.09542\n",
      "X reconstruct loss: 0.09306\n",
      "Y reconstruct loss: 0.12375\n",
      "Epoch 00181: GXY_loss: 6.85784, GY_loss: 1.09218,GYX_loss: 6.83801, GX_loss: 1.09267\n",
      "X reconstruct loss: 0.08934\n",
      "Y reconstruct loss: 0.11720\n",
      "Epoch 00191: GXY_loss: 6.74243, GY_loss: 1.09362,GYX_loss: 6.72005, GX_loss: 1.09331\n",
      "X reconstruct loss: 0.09192\n",
      "Y reconstruct loss: 0.11071\n",
      "Epoch 00201: GXY_loss: 7.05215, GY_loss: 1.07740,GYX_loss: 7.02820, GX_loss: 1.08989\n",
      "X reconstruct loss: 0.08906\n",
      "Y reconstruct loss: 0.12376\n",
      "Epoch 00211: GXY_loss: 7.01229, GY_loss: 1.08156,GYX_loss: 6.99824, GX_loss: 1.07572\n",
      "X reconstruct loss: 0.09241\n",
      "Y reconstruct loss: 0.11917\n",
      "Epoch 00221: GXY_loss: 6.16685, GY_loss: 1.07606,GYX_loss: 6.14743, GX_loss: 1.07977\n",
      "X reconstruct loss: 0.07498\n",
      "Y reconstruct loss: 0.10829\n",
      "Epoch 00231: GXY_loss: 6.38336, GY_loss: 1.07486,GYX_loss: 6.36151, GX_loss: 1.08121\n",
      "X reconstruct loss: 0.07418\n",
      "Y reconstruct loss: 0.11629\n",
      "Epoch 00241: GXY_loss: 6.51837, GY_loss: 1.07694,GYX_loss: 6.50345, GX_loss: 1.07268\n",
      "X reconstruct loss: 0.07620\n",
      "Y reconstruct loss: 0.11882\n",
      "Epoch 00251: GXY_loss: 6.28483, GY_loss: 1.07789,GYX_loss: 6.26392, GX_loss: 1.07838\n",
      "X reconstruct loss: 0.07906\n",
      "Y reconstruct loss: 0.10814\n",
      "Epoch 00261: GXY_loss: 6.25137, GY_loss: 1.07735,GYX_loss: 6.23198, GX_loss: 1.08081\n",
      "X reconstruct loss: 0.08158\n",
      "Y reconstruct loss: 0.10452\n",
      "Epoch 00271: GXY_loss: 5.93013, GY_loss: 1.07548,GYX_loss: 5.91508, GX_loss: 1.07009\n",
      "X reconstruct loss: 0.07273\n",
      "Y reconstruct loss: 0.10263\n",
      "Epoch 00281: GXY_loss: 6.05547, GY_loss: 1.07353,GYX_loss: 6.04199, GX_loss: 1.07321\n",
      "X reconstruct loss: 0.07333\n",
      "Y reconstruct loss: 0.10616\n",
      "Epoch 00291: GXY_loss: 5.90364, GY_loss: 1.06610,GYX_loss: 5.88369, GX_loss: 1.07181\n",
      "X reconstruct loss: 0.07110\n",
      "Y reconstruct loss: 0.10324\n",
      "Epoch 00301: GXY_loss: 5.97389, GY_loss: 1.06998,GYX_loss: 5.95936, GX_loss: 1.06501\n",
      "X reconstruct loss: 0.07158\n",
      "Y reconstruct loss: 0.10508\n",
      "Epoch 00311: GXY_loss: 6.99529, GY_loss: 1.07231,GYX_loss: 6.97555, GX_loss: 1.07385\n",
      "X reconstruct loss: 0.08774\n",
      "Y reconstruct loss: 0.12296\n",
      "Epoch 00321: GXY_loss: 5.87320, GY_loss: 1.06877,GYX_loss: 5.86340, GX_loss: 1.05499\n",
      "X reconstruct loss: 0.06996\n",
      "Y reconstruct loss: 0.10335\n",
      "Epoch 00331: GXY_loss: 6.00167, GY_loss: 1.07658,GYX_loss: 5.99116, GX_loss: 1.05810\n",
      "X reconstruct loss: 0.07144\n",
      "Y reconstruct loss: 0.10616\n",
      "Epoch 00341: GXY_loss: 5.40661, GY_loss: 1.07265,GYX_loss: 5.39843, GX_loss: 1.05517\n",
      "X reconstruct loss: 0.06285\n",
      "Y reconstruct loss: 0.09493\n",
      "Epoch 00351: GXY_loss: 5.81472, GY_loss: 1.06552,GYX_loss: 5.80218, GX_loss: 1.05985\n",
      "X reconstruct loss: 0.07179\n",
      "Y reconstruct loss: 0.09956\n",
      "Epoch 00361: GXY_loss: 5.71545, GY_loss: 1.06966,GYX_loss: 5.70990, GX_loss: 1.05246\n",
      "X reconstruct loss: 0.07129\n",
      "Y reconstruct loss: 0.09685\n",
      "Epoch 00371: GXY_loss: 5.67233, GY_loss: 1.06594,GYX_loss: 5.65975, GX_loss: 1.05488\n",
      "X reconstruct loss: 0.06717\n",
      "Y reconstruct loss: 0.09931\n",
      "Epoch 00381: GXY_loss: 5.11623, GY_loss: 1.06440,GYX_loss: 5.10900, GX_loss: 1.04720\n",
      "X reconstruct loss: 0.05877\n",
      "Y reconstruct loss: 0.08924\n",
      "Epoch 00391: GXY_loss: 5.44097, GY_loss: 1.07634,GYX_loss: 5.43302, GX_loss: 1.05505\n",
      "X reconstruct loss: 0.06962\n",
      "Y reconstruct loss: 0.08930\n",
      "Epoch 00401: GXY_loss: 5.35489, GY_loss: 1.07237,GYX_loss: 5.34492, GX_loss: 1.06095\n",
      "X reconstruct loss: 0.06307\n",
      "Y reconstruct loss: 0.09293\n",
      "Epoch 00411: GXY_loss: 5.83473, GY_loss: 1.06825,GYX_loss: 5.82750, GX_loss: 1.04604\n",
      "X reconstruct loss: 0.07245\n",
      "Y reconstruct loss: 0.09947\n",
      "Epoch 00421: GXY_loss: 5.36447, GY_loss: 1.07175,GYX_loss: 5.35926, GX_loss: 1.04770\n",
      "X reconstruct loss: 0.07300\n",
      "Y reconstruct loss: 0.08331\n",
      "Epoch 00431: GXY_loss: 5.57153, GY_loss: 1.05964,GYX_loss: 5.56387, GX_loss: 1.04408\n",
      "X reconstruct loss: 0.07079\n",
      "Y reconstruct loss: 0.09226\n",
      "Epoch 00441: GXY_loss: 5.11963, GY_loss: 1.06306,GYX_loss: 5.11580, GX_loss: 1.04225\n",
      "X reconstruct loss: 0.06323\n",
      "Y reconstruct loss: 0.08488\n",
      "Epoch 00451: GXY_loss: 5.04358, GY_loss: 1.06183,GYX_loss: 5.03999, GX_loss: 1.04766\n",
      "X reconstruct loss: 0.06124\n",
      "Y reconstruct loss: 0.08434\n",
      "Epoch 00461: GXY_loss: 5.54563, GY_loss: 1.05944,GYX_loss: 5.54116, GX_loss: 1.04105\n",
      "X reconstruct loss: 0.06705\n",
      "Y reconstruct loss: 0.09521\n",
      "Epoch 00471: GXY_loss: 4.99353, GY_loss: 1.06183,GYX_loss: 4.98709, GX_loss: 1.04161\n",
      "X reconstruct loss: 0.06174\n",
      "Y reconstruct loss: 0.08207\n",
      "Epoch 00481: GXY_loss: 5.03112, GY_loss: 1.05594,GYX_loss: 5.01711, GX_loss: 1.05132\n",
      "X reconstruct loss: 0.05843\n",
      "Y reconstruct loss: 0.08655\n",
      "Epoch 00491: GXY_loss: 5.23297, GY_loss: 1.05961,GYX_loss: 5.22202, GX_loss: 1.04982\n",
      "X reconstruct loss: 0.05740\n",
      "Y reconstruct loss: 0.09437\n",
      "Epoch 00501: GXY_loss: 4.83019, GY_loss: 1.05216,GYX_loss: 4.82144, GX_loss: 1.04198\n",
      "X reconstruct loss: 0.05296\n",
      "Y reconstruct loss: 0.08536\n",
      "Epoch 00511: GXY_loss: 5.26266, GY_loss: 1.06488,GYX_loss: 5.25609, GX_loss: 1.04632\n",
      "X reconstruct loss: 0.06645\n",
      "Y reconstruct loss: 0.08636\n",
      "Epoch 00521: GXY_loss: 4.97531, GY_loss: 1.05471,GYX_loss: 4.96780, GX_loss: 1.04165\n",
      "X reconstruct loss: 0.06333\n",
      "Y reconstruct loss: 0.07981\n",
      "Epoch 00531: GXY_loss: 4.94414, GY_loss: 1.05033,GYX_loss: 4.93896, GX_loss: 1.03258\n",
      "X reconstruct loss: 0.05315\n",
      "Y reconstruct loss: 0.08887\n",
      "Epoch 00541: GXY_loss: 5.21828, GY_loss: 1.05596,GYX_loss: 5.20712, GX_loss: 1.04358\n",
      "X reconstruct loss: 0.06487\n",
      "Y reconstruct loss: 0.08631\n",
      "Epoch 00551: GXY_loss: 5.20700, GY_loss: 1.05966,GYX_loss: 5.20278, GX_loss: 1.03696\n",
      "X reconstruct loss: 0.05817\n",
      "Y reconstruct loss: 0.09276\n",
      "Epoch 00561: GXY_loss: 5.12230, GY_loss: 1.05336,GYX_loss: 5.11544, GX_loss: 1.03652\n",
      "X reconstruct loss: 0.06507\n",
      "Y reconstruct loss: 0.08291\n",
      "Epoch 00571: GXY_loss: 5.86746, GY_loss: 1.05400,GYX_loss: 5.85952, GX_loss: 1.04007\n",
      "X reconstruct loss: 0.06813\n",
      "Y reconstruct loss: 0.10473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00581: GXY_loss: 5.26657, GY_loss: 1.05325,GYX_loss: 5.26142, GX_loss: 1.03377\n",
      "X reconstruct loss: 0.06179\n",
      "Y reconstruct loss: 0.09100\n",
      "Epoch 00591: GXY_loss: 4.70063, GY_loss: 1.04678,GYX_loss: 4.69795, GX_loss: 1.03049\n",
      "X reconstruct loss: 0.06516\n",
      "Y reconstruct loss: 0.06877\n",
      "Epoch 00601: GXY_loss: 4.93557, GY_loss: 1.05887,GYX_loss: 4.93591, GX_loss: 1.03202\n",
      "X reconstruct loss: 0.06099\n",
      "Y reconstruct loss: 0.08090\n",
      "Epoch 00611: GXY_loss: 4.72464, GY_loss: 1.05425,GYX_loss: 4.72392, GX_loss: 1.03511\n",
      "X reconstruct loss: 0.05367\n",
      "Y reconstruct loss: 0.08124\n",
      "Epoch 00621: GXY_loss: 4.36163, GY_loss: 1.04647,GYX_loss: 4.35813, GX_loss: 1.03277\n",
      "X reconstruct loss: 0.05082\n",
      "Y reconstruct loss: 0.07185\n",
      "Epoch 00631: GXY_loss: 4.83799, GY_loss: 1.05145,GYX_loss: 4.83854, GX_loss: 1.03005\n",
      "X reconstruct loss: 0.06350\n",
      "Y reconstruct loss: 0.07514\n",
      "Epoch 00641: GXY_loss: 5.29552, GY_loss: 1.04687,GYX_loss: 5.29196, GX_loss: 1.03397\n",
      "X reconstruct loss: 0.05856\n",
      "Y reconstruct loss: 0.09525\n",
      "Epoch 00651: GXY_loss: 4.84614, GY_loss: 1.04304,GYX_loss: 4.83964, GX_loss: 1.03601\n",
      "X reconstruct loss: 0.05693\n",
      "Y reconstruct loss: 0.08185\n",
      "Epoch 00661: GXY_loss: 4.55425, GY_loss: 1.04420,GYX_loss: 4.55293, GX_loss: 1.03518\n",
      "X reconstruct loss: 0.05555\n",
      "Y reconstruct loss: 0.07358\n",
      "Epoch 00671: GXY_loss: 4.81914, GY_loss: 1.05564,GYX_loss: 4.81932, GX_loss: 1.03074\n",
      "X reconstruct loss: 0.05534\n",
      "Y reconstruct loss: 0.08265\n",
      "Epoch 00681: GXY_loss: 4.66523, GY_loss: 1.05104,GYX_loss: 4.66530, GX_loss: 1.03369\n",
      "X reconstruct loss: 0.06004\n",
      "Y reconstruct loss: 0.07286\n",
      "Epoch 00691: GXY_loss: 5.63588, GY_loss: 1.03832,GYX_loss: 5.63182, GX_loss: 1.03154\n",
      "X reconstruct loss: 0.07464\n",
      "Y reconstruct loss: 0.09044\n",
      "Epoch 00701: GXY_loss: 4.35276, GY_loss: 1.04208,GYX_loss: 4.34678, GX_loss: 1.03740\n",
      "X reconstruct loss: 0.05142\n",
      "Y reconstruct loss: 0.07093\n",
      "Epoch 00711: GXY_loss: 4.95024, GY_loss: 1.04661,GYX_loss: 4.94866, GX_loss: 1.03319\n",
      "X reconstruct loss: 0.05725\n",
      "Y reconstruct loss: 0.08506\n",
      "Epoch 00721: GXY_loss: 4.54544, GY_loss: 1.04174,GYX_loss: 4.53966, GX_loss: 1.03923\n",
      "X reconstruct loss: 0.06159\n",
      "Y reconstruct loss: 0.06720\n",
      "Epoch 00731: GXY_loss: 4.91600, GY_loss: 1.04166,GYX_loss: 4.91495, GX_loss: 1.03209\n",
      "X reconstruct loss: 0.06113\n",
      "Y reconstruct loss: 0.08009\n",
      "Epoch 00741: GXY_loss: 4.96081, GY_loss: 1.04554,GYX_loss: 4.95724, GX_loss: 1.03211\n",
      "X reconstruct loss: 0.06687\n",
      "Y reconstruct loss: 0.07579\n",
      "Epoch 00751: GXY_loss: 4.80991, GY_loss: 1.04289,GYX_loss: 4.80764, GX_loss: 1.03285\n",
      "X reconstruct loss: 0.05721\n",
      "Y reconstruct loss: 0.08042\n",
      "Epoch 00761: GXY_loss: 4.71131, GY_loss: 1.04258,GYX_loss: 4.71140, GX_loss: 1.02823\n",
      "X reconstruct loss: 0.05791\n",
      "Y reconstruct loss: 0.07643\n",
      "Epoch 00771: GXY_loss: 4.50248, GY_loss: 1.04164,GYX_loss: 4.49677, GX_loss: 1.03818\n",
      "X reconstruct loss: 0.05130\n",
      "Y reconstruct loss: 0.07609\n",
      "Epoch 00781: GXY_loss: 5.13228, GY_loss: 1.05315,GYX_loss: 5.13728, GX_loss: 1.03765\n",
      "X reconstruct loss: 0.05403\n",
      "Y reconstruct loss: 0.09449\n",
      "Epoch 00791: GXY_loss: 4.59602, GY_loss: 1.04678,GYX_loss: 4.59529, GX_loss: 1.03368\n",
      "X reconstruct loss: 0.05538\n",
      "Y reconstruct loss: 0.07518\n",
      "Epoch 00801: GXY_loss: 5.37950, GY_loss: 1.04510,GYX_loss: 5.37824, GX_loss: 1.03321\n",
      "X reconstruct loss: 0.06596\n",
      "Y reconstruct loss: 0.09073\n",
      "Epoch 00811: GXY_loss: 5.11963, GY_loss: 1.03909,GYX_loss: 5.11616, GX_loss: 1.03224\n",
      "X reconstruct loss: 0.07058\n",
      "Y reconstruct loss: 0.07736\n",
      "Epoch 00821: GXY_loss: 4.68616, GY_loss: 1.03787,GYX_loss: 4.68164, GX_loss: 1.03805\n",
      "X reconstruct loss: 0.05944\n",
      "Y reconstruct loss: 0.07407\n",
      "Epoch 00831: GXY_loss: 4.60719, GY_loss: 1.03711,GYX_loss: 4.60013, GX_loss: 1.03589\n",
      "X reconstruct loss: 0.05734\n",
      "Y reconstruct loss: 0.07344\n",
      "Epoch 00841: GXY_loss: 5.31895, GY_loss: 1.03535,GYX_loss: 5.31282, GX_loss: 1.03664\n",
      "X reconstruct loss: 0.05459\n",
      "Y reconstruct loss: 0.09996\n",
      "Epoch 00851: GXY_loss: 4.46773, GY_loss: 1.04298,GYX_loss: 4.46444, GX_loss: 1.03277\n",
      "X reconstruct loss: 0.05876\n",
      "Y reconstruct loss: 0.06741\n",
      "Epoch 00861: GXY_loss: 4.92281, GY_loss: 1.03958,GYX_loss: 4.92060, GX_loss: 1.03162\n",
      "X reconstruct loss: 0.06649\n",
      "Y reconstruct loss: 0.07489\n",
      "Epoch 00871: GXY_loss: 4.22960, GY_loss: 1.03660,GYX_loss: 4.22930, GX_loss: 1.02777\n",
      "X reconstruct loss: 0.05253\n",
      "Y reconstruct loss: 0.06571\n",
      "Epoch 00881: GXY_loss: 4.64968, GY_loss: 1.03784,GYX_loss: 4.65491, GX_loss: 1.02506\n",
      "X reconstruct loss: 0.05725\n",
      "Y reconstruct loss: 0.07513\n",
      "Epoch 00891: GXY_loss: 4.62016, GY_loss: 1.03602,GYX_loss: 4.62050, GX_loss: 1.02716\n",
      "X reconstruct loss: 0.05107\n",
      "Y reconstruct loss: 0.08023\n",
      "Epoch 00901: GXY_loss: 4.85298, GY_loss: 1.02875,GYX_loss: 4.84951, GX_loss: 1.03039\n",
      "X reconstruct loss: 0.05850\n",
      "Y reconstruct loss: 0.08044\n",
      "Epoch 00911: GXY_loss: 4.65119, GY_loss: 1.03640,GYX_loss: 4.65390, GX_loss: 1.02561\n",
      "X reconstruct loss: 0.05239\n",
      "Y reconstruct loss: 0.07999\n",
      "Epoch 00921: GXY_loss: 4.76502, GY_loss: 1.03732,GYX_loss: 4.76651, GX_loss: 1.02695\n",
      "X reconstruct loss: 0.05352\n",
      "Y reconstruct loss: 0.08262\n",
      "Epoch 00931: GXY_loss: 4.76302, GY_loss: 1.03421,GYX_loss: 4.76197, GX_loss: 1.02900\n",
      "X reconstruct loss: 0.05425\n",
      "Y reconstruct loss: 0.08178\n",
      "Epoch 00941: GXY_loss: 4.72252, GY_loss: 1.03778,GYX_loss: 4.72765, GX_loss: 1.02247\n",
      "X reconstruct loss: 0.05623\n",
      "Y reconstruct loss: 0.07853\n",
      "Epoch 00951: GXY_loss: 4.39592, GY_loss: 1.03393,GYX_loss: 4.40008, GX_loss: 1.01980\n",
      "X reconstruct loss: 0.05583\n",
      "Y reconstruct loss: 0.06799\n",
      "Epoch 00961: GXY_loss: 4.64444, GY_loss: 1.03586,GYX_loss: 4.64292, GX_loss: 1.03027\n",
      "X reconstruct loss: 0.05548\n",
      "Y reconstruct loss: 0.07663\n",
      "Epoch 00971: GXY_loss: 4.36151, GY_loss: 1.03374,GYX_loss: 4.36439, GX_loss: 1.02724\n",
      "X reconstruct loss: 0.05175\n",
      "Y reconstruct loss: 0.07096\n",
      "Epoch 00981: GXY_loss: 4.38417, GY_loss: 1.03773,GYX_loss: 4.38825, GX_loss: 1.02248\n",
      "X reconstruct loss: 0.05883\n",
      "Y reconstruct loss: 0.06464\n",
      "Epoch 00991: GXY_loss: 4.51653, GY_loss: 1.03244,GYX_loss: 4.51895, GX_loss: 1.02310\n",
      "X reconstruct loss: 0.04933\n",
      "Y reconstruct loss: 0.07850\n",
      "Epoch 01001: GXY_loss: 4.05550, GY_loss: 1.03241,GYX_loss: 4.05744, GX_loss: 1.02507\n",
      "X reconstruct loss: 0.04590\n",
      "Y reconstruct loss: 0.06656\n",
      "Epoch 01011: GXY_loss: 4.08084, GY_loss: 1.09069,GYX_loss: 4.11639, GX_loss: 1.03216\n",
      "X reconstruct loss: 0.05342\n",
      "Y reconstruct loss: 0.06108\n",
      "Epoch 01021: GXY_loss: 4.58796, GY_loss: 1.05541,GYX_loss: 4.59396, GX_loss: 1.02112\n",
      "X reconstruct loss: 0.05303\n",
      "Y reconstruct loss: 0.07724\n",
      "Epoch 01031: GXY_loss: 4.85248, GY_loss: 1.04848,GYX_loss: 4.85692, GX_loss: 1.02073\n",
      "X reconstruct loss: 0.05598\n",
      "Y reconstruct loss: 0.08308\n",
      "Epoch 01041: GXY_loss: 4.84032, GY_loss: 1.04349,GYX_loss: 4.83571, GX_loss: 1.03646\n",
      "X reconstruct loss: 0.05311\n",
      "Y reconstruct loss: 0.08554\n",
      "Epoch 01051: GXY_loss: 4.39305, GY_loss: 1.03753,GYX_loss: 4.39365, GX_loss: 1.02340\n",
      "X reconstruct loss: 0.05529\n",
      "Y reconstruct loss: 0.06838\n",
      "Epoch 01061: GXY_loss: 4.39966, GY_loss: 1.03574,GYX_loss: 4.40212, GX_loss: 1.02042\n",
      "X reconstruct loss: 0.05266\n",
      "Y reconstruct loss: 0.07121\n",
      "Epoch 01071: GXY_loss: 4.35954, GY_loss: 1.03595,GYX_loss: 4.36361, GX_loss: 1.02174\n",
      "X reconstruct loss: 0.05764\n",
      "Y reconstruct loss: 0.06496\n",
      "Epoch 01081: GXY_loss: 4.77135, GY_loss: 1.03159,GYX_loss: 4.77459, GX_loss: 1.02313\n",
      "X reconstruct loss: 0.05674\n",
      "Y reconstruct loss: 0.07959\n",
      "Epoch 01091: GXY_loss: 4.76452, GY_loss: 1.03147,GYX_loss: 4.76784, GX_loss: 1.02122\n",
      "X reconstruct loss: 0.06196\n",
      "Y reconstruct loss: 0.07410\n",
      "Epoch 01101: GXY_loss: 4.44993, GY_loss: 1.03476,GYX_loss: 4.45332, GX_loss: 1.02225\n",
      "X reconstruct loss: 0.04993\n",
      "Y reconstruct loss: 0.07569\n",
      "Epoch 01111: GXY_loss: 4.09975, GY_loss: 1.02952,GYX_loss: 4.10166, GX_loss: 1.02330\n",
      "X reconstruct loss: 0.04595\n",
      "Y reconstruct loss: 0.06794\n",
      "Epoch 01121: GXY_loss: 4.44148, GY_loss: 1.03286,GYX_loss: 4.44175, GX_loss: 1.02783\n",
      "X reconstruct loss: 0.05170\n",
      "Y reconstruct loss: 0.07362\n",
      "Epoch 01131: GXY_loss: 4.37362, GY_loss: 1.02961,GYX_loss: 4.37432, GX_loss: 1.02565\n",
      "X reconstruct loss: 0.05559\n",
      "Y reconstruct loss: 0.06744\n",
      "Epoch 01141: GXY_loss: 5.08923, GY_loss: 1.02918,GYX_loss: 5.09421, GX_loss: 1.01934\n",
      "X reconstruct loss: 0.06521\n",
      "Y reconstruct loss: 0.08172\n",
      "Epoch 01151: GXY_loss: 4.44209, GY_loss: 1.03926,GYX_loss: 4.44533, GX_loss: 1.02252\n",
      "X reconstruct loss: 0.05475\n",
      "Y reconstruct loss: 0.07060\n",
      "Epoch 01161: GXY_loss: 4.80123, GY_loss: 1.03365,GYX_loss: 4.80247, GX_loss: 1.02619\n",
      "X reconstruct loss: 0.05288\n",
      "Y reconstruct loss: 0.08447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01171: GXY_loss: 4.81780, GY_loss: 1.02923,GYX_loss: 4.82046, GX_loss: 1.02059\n",
      "X reconstruct loss: 0.05215\n",
      "Y reconstruct loss: 0.08566\n",
      "Epoch 01181: GXY_loss: 4.54399, GY_loss: 1.02763,GYX_loss: 4.54455, GX_loss: 1.02514\n",
      "X reconstruct loss: 0.05921\n",
      "Y reconstruct loss: 0.06949\n",
      "Epoch 01191: GXY_loss: 4.61797, GY_loss: 1.02018,GYX_loss: 4.61966, GX_loss: 1.01647\n",
      "X reconstruct loss: 0.06616\n",
      "Y reconstruct loss: 0.06488\n",
      "Epoch 01201: GXY_loss: 4.17591, GY_loss: 1.02400,GYX_loss: 4.17389, GX_loss: 1.02513\n",
      "X reconstruct loss: 0.05146\n",
      "Y reconstruct loss: 0.06489\n",
      "Epoch 01211: GXY_loss: 4.67313, GY_loss: 1.02632,GYX_loss: 4.67228, GX_loss: 1.02509\n",
      "X reconstruct loss: 0.06182\n",
      "Y reconstruct loss: 0.07114\n",
      "Epoch 01221: GXY_loss: 4.62722, GY_loss: 1.02655,GYX_loss: 4.62724, GX_loss: 1.02502\n",
      "X reconstruct loss: 0.05778\n",
      "Y reconstruct loss: 0.07367\n",
      "Epoch 01231: GXY_loss: 4.42469, GY_loss: 1.02564,GYX_loss: 4.42158, GX_loss: 1.02976\n",
      "X reconstruct loss: 0.05114\n",
      "Y reconstruct loss: 0.07356\n",
      "Epoch 01241: GXY_loss: 4.72308, GY_loss: 1.02572,GYX_loss: 4.72081, GX_loss: 1.02775\n",
      "X reconstruct loss: 0.05136\n",
      "Y reconstruct loss: 0.08327\n",
      "Epoch 01251: GXY_loss: 4.20808, GY_loss: 1.02330,GYX_loss: 4.21094, GX_loss: 1.01707\n",
      "X reconstruct loss: 0.05402\n",
      "Y reconstruct loss: 0.06343\n",
      "Epoch 01261: GXY_loss: 4.40678, GY_loss: 1.02499,GYX_loss: 4.40857, GX_loss: 1.01897\n",
      "X reconstruct loss: 0.05117\n",
      "Y reconstruct loss: 0.07291\n",
      "Epoch 01271: GXY_loss: 4.29778, GY_loss: 1.02114,GYX_loss: 4.29699, GX_loss: 1.02124\n",
      "X reconstruct loss: 0.05049\n",
      "Y reconstruct loss: 0.06991\n",
      "Epoch 01281: GXY_loss: 4.34431, GY_loss: 1.02542,GYX_loss: 4.34854, GX_loss: 1.01684\n",
      "X reconstruct loss: 0.04693\n",
      "Y reconstruct loss: 0.07510\n",
      "Epoch 01291: GXY_loss: 3.97843, GY_loss: 1.02811,GYX_loss: 3.97997, GX_loss: 1.02158\n",
      "X reconstruct loss: 0.04775\n",
      "Y reconstruct loss: 0.06208\n",
      "Epoch 01301: GXY_loss: 4.26005, GY_loss: 1.02309,GYX_loss: 4.26159, GX_loss: 1.01902\n",
      "X reconstruct loss: 0.05137\n",
      "Y reconstruct loss: 0.06780\n",
      "Epoch 01311: GXY_loss: 4.00480, GY_loss: 1.02727,GYX_loss: 4.00192, GX_loss: 1.02757\n",
      "X reconstruct loss: 0.04513\n",
      "Y reconstruct loss: 0.06553\n",
      "Epoch 01321: GXY_loss: 4.22704, GY_loss: 1.02931,GYX_loss: 4.22561, GX_loss: 1.02626\n",
      "X reconstruct loss: 0.04519\n",
      "Y reconstruct loss: 0.07293\n",
      "Epoch 01331: GXY_loss: 4.21632, GY_loss: 1.02370,GYX_loss: 4.22041, GX_loss: 1.01818\n",
      "X reconstruct loss: 0.05390\n",
      "Y reconstruct loss: 0.06386\n",
      "Epoch 01341: GXY_loss: 4.52499, GY_loss: 1.02002,GYX_loss: 4.51798, GX_loss: 1.03074\n",
      "X reconstruct loss: 0.05762\n",
      "Y reconstruct loss: 0.07033\n",
      "Epoch 01351: GXY_loss: 4.77308, GY_loss: 1.02743,GYX_loss: 4.77454, GX_loss: 1.02495\n",
      "X reconstruct loss: 0.05638\n",
      "Y reconstruct loss: 0.07999\n",
      "Epoch 01361: GXY_loss: 4.10922, GY_loss: 1.02635,GYX_loss: 4.10827, GX_loss: 1.02501\n",
      "X reconstruct loss: 0.05242\n",
      "Y reconstruct loss: 0.06174\n",
      "Epoch 01371: GXY_loss: 3.89044, GY_loss: 1.02297,GYX_loss: 3.89216, GX_loss: 1.01909\n",
      "X reconstruct loss: 0.04709\n",
      "Y reconstruct loss: 0.05976\n",
      "Epoch 01381: GXY_loss: 4.20969, GY_loss: 1.02919,GYX_loss: 4.20983, GX_loss: 1.02601\n",
      "X reconstruct loss: 0.04583\n",
      "Y reconstruct loss: 0.07175\n",
      "Epoch 01391: GXY_loss: 4.54449, GY_loss: 1.03168,GYX_loss: 4.54859, GX_loss: 1.01434\n",
      "X reconstruct loss: 0.05139\n",
      "Y reconstruct loss: 0.07726\n",
      "Epoch 01401: GXY_loss: 4.16009, GY_loss: 1.02283,GYX_loss: 4.15949, GX_loss: 1.02565\n",
      "X reconstruct loss: 0.04715\n",
      "Y reconstruct loss: 0.06869\n",
      "Epoch 01411: GXY_loss: 3.95937, GY_loss: 1.02514,GYX_loss: 3.96070, GX_loss: 1.02402\n",
      "X reconstruct loss: 0.04254\n",
      "Y reconstruct loss: 0.06666\n",
      "Epoch 01421: GXY_loss: 4.73283, GY_loss: 1.01977,GYX_loss: 4.72871, GX_loss: 1.03043\n",
      "X reconstruct loss: 0.05343\n",
      "Y reconstruct loss: 0.08147\n",
      "Epoch 01431: GXY_loss: 4.33438, GY_loss: 1.02555,GYX_loss: 4.33633, GX_loss: 1.02182\n",
      "X reconstruct loss: 0.05316\n",
      "Y reconstruct loss: 0.06856\n",
      "Epoch 01441: GXY_loss: 4.25118, GY_loss: 1.01870,GYX_loss: 4.24905, GX_loss: 1.02267\n",
      "X reconstruct loss: 0.04951\n",
      "Y reconstruct loss: 0.06930\n",
      "Epoch 01451: GXY_loss: 4.42937, GY_loss: 1.02719,GYX_loss: 4.43170, GX_loss: 1.01945\n",
      "X reconstruct loss: 0.05392\n",
      "Y reconstruct loss: 0.07093\n",
      "Epoch 01461: GXY_loss: 4.01329, GY_loss: 1.03005,GYX_loss: 4.01343, GX_loss: 1.02393\n",
      "X reconstruct loss: 0.04522\n",
      "Y reconstruct loss: 0.06577\n",
      "Epoch 01471: GXY_loss: 4.57939, GY_loss: 1.02320,GYX_loss: 4.57860, GX_loss: 1.02313\n",
      "X reconstruct loss: 0.05131\n",
      "Y reconstruct loss: 0.07851\n",
      "Epoch 01481: GXY_loss: 4.42239, GY_loss: 1.02951,GYX_loss: 4.42103, GX_loss: 1.02482\n",
      "X reconstruct loss: 0.05102\n",
      "Y reconstruct loss: 0.07356\n",
      "Epoch 01491: GXY_loss: 4.30981, GY_loss: 1.02045,GYX_loss: 4.30720, GX_loss: 1.02474\n",
      "X reconstruct loss: 0.05194\n",
      "Y reconstruct loss: 0.06885\n",
      "Epoch 01501: GXY_loss: 4.50675, GY_loss: 1.02338,GYX_loss: 4.50543, GX_loss: 1.02483\n",
      "X reconstruct loss: 0.05158\n",
      "Y reconstruct loss: 0.07582\n",
      "Epoch 01511: GXY_loss: 4.57388, GY_loss: 1.02559,GYX_loss: 4.57269, GX_loss: 1.02478\n",
      "X reconstruct loss: 0.05203\n",
      "Y reconstruct loss: 0.07761\n",
      "Epoch 01521: GXY_loss: 4.17440, GY_loss: 1.02336,GYX_loss: 4.17453, GX_loss: 1.02471\n",
      "X reconstruct loss: 0.05527\n",
      "Y reconstruct loss: 0.06109\n",
      "Epoch 01531: GXY_loss: 4.06944, GY_loss: 1.02714,GYX_loss: 4.07379, GX_loss: 1.01994\n",
      "X reconstruct loss: 0.04507\n",
      "Y reconstruct loss: 0.06783\n",
      "Epoch 01541: GXY_loss: 3.94989, GY_loss: 1.01900,GYX_loss: 3.95001, GX_loss: 1.01852\n",
      "X reconstruct loss: 0.04995\n",
      "Y reconstruct loss: 0.05883\n",
      "Epoch 01551: GXY_loss: 4.10961, GY_loss: 1.02769,GYX_loss: 4.11532, GX_loss: 1.01533\n",
      "X reconstruct loss: 0.04550\n",
      "Y reconstruct loss: 0.06870\n",
      "Epoch 01561: GXY_loss: 4.12825, GY_loss: 1.02058,GYX_loss: 4.12288, GX_loss: 1.02498\n",
      "X reconstruct loss: 0.05306\n",
      "Y reconstruct loss: 0.06166\n",
      "Epoch 01571: GXY_loss: 4.05146, GY_loss: 1.02323,GYX_loss: 4.03835, GX_loss: 1.04177\n",
      "X reconstruct loss: 0.04889\n",
      "Y reconstruct loss: 0.06332\n",
      "Epoch 01581: GXY_loss: 5.06249, GY_loss: 1.02035,GYX_loss: 5.05384, GX_loss: 1.03266\n",
      "X reconstruct loss: 0.05050\n",
      "Y reconstruct loss: 0.09537\n",
      "Epoch 01591: GXY_loss: 4.27774, GY_loss: 1.02166,GYX_loss: 4.27431, GX_loss: 1.02441\n",
      "X reconstruct loss: 0.05365\n",
      "Y reconstruct loss: 0.06606\n",
      "Epoch 01601: GXY_loss: 4.56154, GY_loss: 1.02624,GYX_loss: 4.56409, GX_loss: 1.04532\n",
      "X reconstruct loss: 0.05550\n",
      "Y reconstruct loss: 0.07376\n",
      "Epoch 01611: GXY_loss: 4.32636, GY_loss: 1.02079,GYX_loss: 4.32354, GX_loss: 1.02656\n",
      "X reconstruct loss: 0.04947\n",
      "Y reconstruct loss: 0.07190\n",
      "Epoch 01621: GXY_loss: 4.15381, GY_loss: 1.02982,GYX_loss: 4.15586, GX_loss: 1.02356\n",
      "X reconstruct loss: 0.04878\n",
      "Y reconstruct loss: 0.06693\n",
      "Epoch 01631: GXY_loss: 4.25275, GY_loss: 1.02601,GYX_loss: 4.25123, GX_loss: 1.02741\n",
      "X reconstruct loss: 0.04578\n",
      "Y reconstruct loss: 0.07319\n",
      "Epoch 01641: GXY_loss: 4.32804, GY_loss: 1.01763,GYX_loss: 4.32368, GX_loss: 1.02517\n",
      "X reconstruct loss: 0.05876\n",
      "Y reconstruct loss: 0.06258\n",
      "Epoch 01651: GXY_loss: 4.10269, GY_loss: 1.02011,GYX_loss: 4.09936, GX_loss: 1.02454\n",
      "X reconstruct loss: 0.05136\n",
      "Y reconstruct loss: 0.06251\n",
      "Epoch 01661: GXY_loss: 4.28065, GY_loss: 1.01994,GYX_loss: 4.27750, GX_loss: 1.02529\n",
      "X reconstruct loss: 0.04992\n",
      "Y reconstruct loss: 0.06989\n",
      "Epoch 01671: GXY_loss: 4.43672, GY_loss: 1.02607,GYX_loss: 4.43808, GX_loss: 1.02140\n",
      "X reconstruct loss: 0.05768\n",
      "Y reconstruct loss: 0.06742\n",
      "Epoch 01681: GXY_loss: 4.35209, GY_loss: 1.02140,GYX_loss: 4.35148, GX_loss: 1.02000\n",
      "X reconstruct loss: 0.04941\n",
      "Y reconstruct loss: 0.07278\n",
      "Epoch 01691: GXY_loss: 4.09085, GY_loss: 1.02076,GYX_loss: 4.09170, GX_loss: 1.01907\n",
      "X reconstruct loss: 0.04751\n",
      "Y reconstruct loss: 0.06601\n",
      "Epoch 01701: GXY_loss: 4.05736, GY_loss: 1.01844,GYX_loss: 4.05452, GX_loss: 1.02210\n",
      "X reconstruct loss: 0.04151\n",
      "Y reconstruct loss: 0.07084\n",
      "Epoch 01711: GXY_loss: 4.54774, GY_loss: 1.02509,GYX_loss: 4.54885, GX_loss: 1.01770\n",
      "X reconstruct loss: 0.06518\n",
      "Y reconstruct loss: 0.06356\n",
      "Epoch 01721: GXY_loss: 4.30947, GY_loss: 1.02460,GYX_loss: 4.30939, GX_loss: 1.02211\n",
      "X reconstruct loss: 0.04787\n",
      "Y reconstruct loss: 0.07298\n",
      "Epoch 01731: GXY_loss: 4.16839, GY_loss: 1.01849,GYX_loss: 4.17055, GX_loss: 1.01466\n",
      "X reconstruct loss: 0.04755\n",
      "Y reconstruct loss: 0.06850\n",
      "Epoch 01741: GXY_loss: 4.15735, GY_loss: 1.02844,GYX_loss: 4.16274, GX_loss: 1.01537\n",
      "X reconstruct loss: 0.05431\n",
      "Y reconstruct loss: 0.06152\n",
      "Epoch 01751: GXY_loss: 3.93215, GY_loss: 1.02172,GYX_loss: 3.93361, GX_loss: 1.01715\n",
      "X reconstruct loss: 0.04722\n",
      "Y reconstruct loss: 0.06101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01761: GXY_loss: 3.94093, GY_loss: 1.02451,GYX_loss: 3.94516, GX_loss: 1.01485\n",
      "X reconstruct loss: 0.04717\n",
      "Y reconstruct loss: 0.06140\n",
      "Epoch 01771: GXY_loss: 4.35597, GY_loss: 1.02393,GYX_loss: 4.36038, GX_loss: 1.01470\n",
      "X reconstruct loss: 0.05539\n",
      "Y reconstruct loss: 0.06702\n",
      "Epoch 01781: GXY_loss: 4.54651, GY_loss: 1.03212,GYX_loss: 4.55123, GX_loss: 1.01457\n",
      "X reconstruct loss: 0.04816\n",
      "Y reconstruct loss: 0.08061\n",
      "Epoch 01791: GXY_loss: 3.97509, GY_loss: 1.02004,GYX_loss: 3.97207, GX_loss: 1.02159\n",
      "X reconstruct loss: 0.05053\n",
      "Y reconstruct loss: 0.05907\n",
      "Epoch 01801: GXY_loss: 4.31600, GY_loss: 1.02659,GYX_loss: 4.31657, GX_loss: 1.02172\n",
      "X reconstruct loss: 0.05445\n",
      "Y reconstruct loss: 0.06663\n",
      "Epoch 01811: GXY_loss: 3.84890, GY_loss: 1.02337,GYX_loss: 3.85342, GX_loss: 1.01443\n",
      "X reconstruct loss: 0.05224\n",
      "Y reconstruct loss: 0.05327\n",
      "Epoch 01821: GXY_loss: 3.85558, GY_loss: 1.02489,GYX_loss: 3.85034, GX_loss: 1.02908\n",
      "X reconstruct loss: 0.05045\n",
      "Y reconstruct loss: 0.05528\n",
      "Epoch 01831: GXY_loss: 3.76945, GY_loss: 1.02519,GYX_loss: 3.76293, GX_loss: 1.03106\n",
      "X reconstruct loss: 0.04917\n",
      "Y reconstruct loss: 0.05365\n",
      "Epoch 01841: GXY_loss: 4.21151, GY_loss: 1.02270,GYX_loss: 4.20948, GX_loss: 1.02200\n",
      "X reconstruct loss: 0.05396\n",
      "Y reconstruct loss: 0.06358\n",
      "Epoch 01851: GXY_loss: 4.43725, GY_loss: 1.02320,GYX_loss: 4.43448, GX_loss: 1.02478\n",
      "X reconstruct loss: 0.05404\n",
      "Y reconstruct loss: 0.07104\n",
      "Epoch 01861: GXY_loss: 4.36029, GY_loss: 1.02012,GYX_loss: 4.36001, GX_loss: 1.01794\n",
      "X reconstruct loss: 0.04824\n",
      "Y reconstruct loss: 0.07423\n",
      "Epoch 01871: GXY_loss: 3.85095, GY_loss: 1.02131,GYX_loss: 3.85006, GX_loss: 1.02089\n",
      "X reconstruct loss: 0.04668\n",
      "Y reconstruct loss: 0.05884\n",
      "Epoch 01881: GXY_loss: 4.04840, GY_loss: 1.01985,GYX_loss: 4.04546, GX_loss: 1.02071\n",
      "X reconstruct loss: 0.04457\n",
      "Y reconstruct loss: 0.06749\n",
      "Epoch 01891: GXY_loss: 3.95927, GY_loss: 1.01827,GYX_loss: 3.95732, GX_loss: 1.02067\n",
      "X reconstruct loss: 0.04642\n",
      "Y reconstruct loss: 0.06267\n",
      "Epoch 01901: GXY_loss: 4.42658, GY_loss: 1.01974,GYX_loss: 4.42484, GX_loss: 1.01998\n",
      "X reconstruct loss: 0.04350\n",
      "Y reconstruct loss: 0.08117\n",
      "Epoch 01911: GXY_loss: 4.37211, GY_loss: 1.02685,GYX_loss: 4.37471, GX_loss: 1.01970\n",
      "X reconstruct loss: 0.04769\n",
      "Y reconstruct loss: 0.07530\n",
      "Epoch 01921: GXY_loss: 3.96440, GY_loss: 1.01974,GYX_loss: 3.96153, GX_loss: 1.02206\n",
      "X reconstruct loss: 0.04998\n",
      "Y reconstruct loss: 0.05928\n",
      "Epoch 01931: GXY_loss: 3.84697, GY_loss: 1.02196,GYX_loss: 3.84835, GX_loss: 1.01709\n",
      "X reconstruct loss: 0.04449\n",
      "Y reconstruct loss: 0.06090\n",
      "Epoch 01941: GXY_loss: 4.13221, GY_loss: 1.02299,GYX_loss: 4.12932, GX_loss: 1.02658\n",
      "X reconstruct loss: 0.04211\n",
      "Y reconstruct loss: 0.07283\n",
      "Epoch 01951: GXY_loss: 3.78360, GY_loss: 1.02298,GYX_loss: 3.77810, GX_loss: 1.02578\n",
      "X reconstruct loss: 0.04264\n",
      "Y reconstruct loss: 0.06068\n",
      "Epoch 01961: GXY_loss: 4.51302, GY_loss: 1.02353,GYX_loss: 4.51367, GX_loss: 1.02221\n",
      "X reconstruct loss: 0.04753\n",
      "Y reconstruct loss: 0.08011\n",
      "Epoch 01971: GXY_loss: 4.13292, GY_loss: 1.02125,GYX_loss: 4.12945, GX_loss: 1.02429\n",
      "X reconstruct loss: 0.04853\n",
      "Y reconstruct loss: 0.06639\n",
      "Epoch 01981: GXY_loss: 4.26817, GY_loss: 1.02458,GYX_loss: 4.26957, GX_loss: 1.02030\n",
      "X reconstruct loss: 0.05460\n",
      "Y reconstruct loss: 0.06488\n",
      "Epoch 01991: GXY_loss: 4.19457, GY_loss: 1.02338,GYX_loss: 4.19600, GX_loss: 1.02067\n",
      "X reconstruct loss: 0.05750\n",
      "Y reconstruct loss: 0.05953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GXY_optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "DY_optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "GYX_optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "DX_optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "GXY_losses = []\n",
    "DY_losses = []\n",
    "GYX_losses = []\n",
    "DX_losses = []\n",
    "is_training = True\n",
    "for i in range(epoch):\n",
    "\n",
    "            X = Texas_data_annual.make_one_shot_iterator().get_next()\n",
    "            Y = Pacific_data_annual.make_one_shot_iterator().get_next()\n",
    "            with tf.GradientTape() as GXY_tap, tf.GradientTape() as DY_tap, tf.GradientTape() as GYX_tap, tf.GradientTape() as DX_tap:\n",
    "                Y_gen= GeneratorXY(X,is_training)\n",
    "                X_rec= GeneratorYX(Y_gen,is_training)\n",
    "                Dis_Y = DiscriminatorY(Y,is_training)\n",
    "                Dis_Y_gen = DiscriminatorY(Y_gen,is_training)\n",
    "                \n",
    "                X_gen = GeneratorYX(Y,is_training)\n",
    "                Y_rec = GeneratorXY(X_gen,is_training)\n",
    "                Dis_X = DiscriminatorX(X,is_training)\n",
    "                Dis_X_gen = DiscriminatorX(X_gen,is_training)\n",
    "                \n",
    "                X_rec_loss =tf.cast(tf.losses.absolute_difference(X,X_rec),'float64' )\n",
    "                Y_rec_loss =tf.cast(tf.losses.absolute_difference(Y,Y_rec),'float64')\n",
    "                \n",
    "                DY_loss =( tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(Dis_Y),logits=Dis_Y)+\n",
    "                        tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(Dis_Y_gen),logits=Dis_Y_gen) )\n",
    "                \n",
    "                \n",
    "                #DY_loss = tf.reduce_mean(tf.log(1-Dis_Y)+tf.log(Dis_Y_gen))\n",
    "                \n",
    "                DX_loss =( tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(Dis_X),logits=Dis_X)+\n",
    "                        tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(Dis_X_gen),logits=Dis_X_gen)) \n",
    "                \n",
    "                #DX_loss = tf.reduce_mean(tf.log(1-Dis_X)+tf.log(Dis_X_gen))\n",
    "                \n",
    "                GXY_loss =( tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(Dis_Y_gen),logits=Dis_Y_gen)\n",
    "                            +30*(tf.cast(tf.losses.mean_squared_error(X,X_rec),'float64' )\n",
    "                                 + tf.cast(tf.losses.mean_squared_error(Y,Y_rec),'float64')))\n",
    "\n",
    "                GYX_loss =(tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(Dis_X_gen),logits=Dis_X_gen)\n",
    "                        +30*(tf.cast(tf.losses.mean_squared_error(X,X_rec),'float64' )\n",
    "                             + tf.cast(tf.losses.mean_squared_error(Y,Y_rec),'float64')))\n",
    "\n",
    "            GXY_grad = GXY_tap.gradient(GXY_loss,GeneratorXY.variables)\n",
    "            DY_grad = DY_tap.gradient(DY_loss,DiscriminatorY.variables)\n",
    "            \n",
    "            GYX_grad = GYX_tap.gradient(GYX_loss,GeneratorYX.variables)\n",
    "            DX_grad = DX_tap.gradient(DX_loss,DiscriminatorX.variables)\n",
    "\n",
    "            GXY_optimizer.apply_gradients(zip(GXY_grad,GeneratorXY.variables))\n",
    "            DY_optimizer.apply_gradients(zip(DY_grad,DiscriminatorY.variables))\n",
    "            GYX_optimizer.apply_gradients(zip(GYX_grad,GeneratorYX.variables))\n",
    "            DX_optimizer.apply_gradients(zip(DX_grad,DiscriminatorX.variables))\n",
    "            \n",
    "            GXY_losses.append(GXY_loss)\n",
    "            DY_losses.append(DY_loss)\n",
    "            GYX_losses.append(GYX_loss)\n",
    "            DX_losses.append(DX_loss)\n",
    "            if i % 10 == 0 :\n",
    "                print('Epoch {:05d}: GXY_loss: {:.5f}, GY_loss: {:.5f},GYX_loss: {:.5f}, GX_loss: {:.5f}'.format(i + 1,GXY_loss,DY_loss,GYX_loss,DX_loss))    \n",
    "                print('X reconstruct loss: {:.5f}'.format(X_rec_loss))\n",
    "                print('Y reconstruct loss: {:.5f}'.format(Y_rec_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_GeneratorXY = tf.train.Checkpoint(GeneratorXY=GeneratorXY)\n",
    "checkpoint_DiscriminatorY=tf.train.Checkpoint(DiscriminatorY=DiscriminatorY)\n",
    "checkpoint_GeneratorYX = tf.train.Checkpoint(GeneratorYX=GeneratorYX)\n",
    "checkpoint_DiscriminatorX = tf.train.Checkpoint(DiscriminatorX=DiscriminatorX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Model/DiscriminatorY-1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_GeneratorXY.save('./Model/GeneratorXY')\n",
    "checkpoint_GeneratorYX.save('./Model/GeneratorYX')\n",
    "checkpoint_DiscriminatorY.save('./Model/DiscriminatorY')\n",
    "checkpoint_DiscriminatorX.save('./Model/DiscriminatorX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(GXY_losses)\n",
    "np.save('./Loss/GXY_losses.npy',GXY_losses)\n",
    "np.save('./Loss/DY_losses.npy',np.array(DY_losses))\n",
    "np.save('./Loss/DX_losses.npy',np.array(DX_losses))\n",
    "np.save('./Loss/GYX_losses.npy',np.array(GYX_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=15\n",
    "GeneratorXY = CycleGeneratorXY(input_shape)\n",
    "DiscriminatorY= CycleDiscriminatorY()\n",
    "GeneratorYX = CycleGeneratorYX(input_shape)\n",
    "DiscriminatorX= CycleDiscriminatorX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_GeneratorXY = tf.train.Checkpoint(GeneratorXY=GeneratorXY)\n",
    "#checkpoint_DiscriminatorY=tf.train.Checkpoint(DiscriminatorY=DiscriminatorY)\n",
    "checkpoint_GeneratorYX = tf.train.Checkpoint(GeneratorYX=GeneratorYX)\n",
    "#checkpoint_DiscriminatorX = tf.train.Checkpoint(DiscriminatorX=DiscriminatorX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_GeneratorXY.restore('./Model/GeneratorXY')\n",
    "checkpoint_GeneratorYX.restore('./Model/GeneratorYX')\n",
    "\n",
    "\n",
    "#checkpoint_DiscriminatorY.restore('./Model/DiscriminatorY')\n",
    "#checkpoint_DiscriminatorX.restore('./Model/DiscriminatorX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
